<?xml version="1.0" encoding="utf-8" ?>
<!--日志配置   效果:不同级别日志配置到不同的日志文件中,且只输出自身级别的日志信息
                https://blog.csdn.net/tianyaleixiaowu/article/details/73327752
-->
<!--
日志级别查看 shift+ctrl+r ===> level    数值越大级别越高,重要性越大
    ERROR(40, "ERROR"),
    WARN(30, "WARN"),
    INFO(20, "INFO"),
    DEBUG(10, "DEBUG"),
    TRACE(0, "TRACE");
-->


<configuration>
    <springProfile name="dev | loc">
        <!-- configuration to be enabled when the "dev" or "staging" profiles are active -->
    </springProfile>
    <property name="appName" value="system-management"/>
    <!--配置日志输出格式-->
    <!--   简单配置项    将日志输出到控制台-->
    <appender name="consoleLog"
              class="ch.qos.logback.core.ConsoleAppender">    <!--ConsoleAppender,这个Appender将日志输出到console，更准确的说是System.out 或者System.err。-->
        <encoder>
            <!-- <pattern>%red(%d{yyyy-MM-dd HH:mm:ss.SSS}) %highlight(%-5level) %green([%thread]) %boldMagenta(%logger{10}) - %cyan(%msg%n)</pattern>  -->

            <pattern>
                {
                "timestamp":"%date{yyyy-MM-dd HH:mm:ss.SSS}",
                "app": "${APP_NAME}","thread": "%thread", "logLevel": "%level", "message": "%message","logger":"%logger"
                }\n
            </pattern>
            <!-- 控制台也要使用UTF-8，不要使用GBK，否则会中文乱码 -->
            <charset>UTF-8</charset>
        </encoder>
    </appender>


    <!-- 配置debug级别日志,实现分离文件日志配置 -->
    <appender name="fileDebugLog"
              class="ch.qos.logback.core.rolling.RollingFileAppender">        <!--RollingFileAppender继承了FileAppender,提供了日志自动切换功能-->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">  <!-- 设置过滤器掉了指定级别的日志-->
            <level>DEBUG</level>                     <!--设置拦截的对象为DEBUG级别日志-->
            <onMatch>ACCEPT</onMatch>                     <!-- 当遇到了DEBUG级别时,启用改段配置.-->
            <onMismatch>DENY</onMismatch>                     <!-- 没有遇到DEBUG级别日志时,屏蔽改段配置-->
        </filter>
        <encoder>
            <pattern>
                %d - %c- %msg%n
            </pattern>
            <charset>UTF-8</charset>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>./log/${appname}/debug.%d.log</fileNamePattern>


        </rollingPolicy>
    </appender>

    <!--分离配置Info级别日志-->
    <appender name="fileInfoLog" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.LevelFilter">   <!--由于error的级别比info高,直接过滤不行,这里需要拦截掉error日志-->
            <level>INFO</level>                     <!--设置拦截的对象为INFO级别日志-->
            <onMatch>ACCEPT</onMatch>               <!-- 当遇到了info级别时,启用改段配置.-->
            <onMismatch>DENY</onMismatch>           <!-- 没有遇到info级别日志时,屏蔽改段配置-->
        </filter>
        <encoder>
            <pattern>
                %d - %c - %msg%n
            </pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!--设置滚动策略  按时间策略来生成日志-->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!--配置生成路径-->
            <fileNamePattern>./log/${appname}/info.%d.log</fileNamePattern>
        </rollingPolicy>
    </appender>


    <!-- 配置error级别日志,单独生成日志文件,跟info日志分离开来,且info日志文件只显示info级别日志,error级别日志只显示error日志 -->
    <!--日志分离需要用来过滤 filter-->
    <appender name="fileErrorLog" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>ERROR</level>         <!-- ThresholdFilter过滤器,只有级别比ERROR高的日志才能被输出到error.%d.log文件中-->
        </filter>
        <encoder>
            <pattern>
                %d - %c - %msg%n
            </pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!--设置滚动策略  按时间策略来生成日志-->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!--配置生成路径-->
            <fileNamePattern>./log/${appname}/error.%d.log</fileNamePattern>
        </rollingPolicy>
    </appender>


    <!-- 读取配置文件中kafka的信息 -->
    <springProperty scope="context" name="isSend"
                    source="log.config.kafka.isSend" defalutValue="false"/>
    <springProperty scope="context" name="bootstrapServers"
                    source="log.config.kafka.bootstrapServers" defalutValue="localhost:9092"/>
    <springProperty scope="context" name="topic"
                    source="log.config.kafka.topic" defalutValue="springbootLoggerInfo"/>
    <springProperty scope="context" name="batchSize"
                    source="log.config.kafka.batchSize" defalutValue="1"/>
    <springProperty scope="context" name="lingerMs"
                    source="log.config.kafka.lingerMs" defalutValue="1000"/>
    <springProperty scope="context" name="compressionType"
                    source="log.config.kafka.compressionType" defalutValue="gzip"/>
    <springProperty scope="context" name="retries"
                    source="log.config.kafka.retries" defalutValue="3"/>
    <springProperty scope="context" name="maxRequestSize"
                    source="log.config.kafka.maxRequestSize" defalutValue="5242880"/>

    <appender name="KAFKA" class="com.unicom.admin.util.KafkaAppender">
        <!-- encoder必须配置, 日志格式 -->
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <!--<pattern>-->
            <!--%red(%d{yyyy-MM-dd HH:mm:ss.SSS}) %highlight(%-5level) %green([%thread]) %boldMagenta(%logger{10}) - %cyan(%msg%n)-->
            <!--</pattern>-->
            <!--为了便于分析将日志数据转为json格式-->
            <pattern>
                {
                "timestamp":"%date{yyyy-MM-dd HH:mm:ss.SSS}",
                "app": "${APP_NAME}","thread": "%thread", "logLevel": "%level", "message": "%message","logger":"%logger"
                }\n
            </pattern>
            <!-- 控制台也要使用UTF-8，不要使用GBK，否则会中文乱码 -->
            <charset>UTF-8</charset>
            <!--<pattern>-->
            <!--{-->
            <!--"timestamp":"%date{yyyy-MM-dd HH:mm:ss.SSS}",-->
            <!--"app": "${APP_NAME}",-->
            <!--"logLevel": "%level",-->
            <!--"message": "%message"-->
            <!--}\n-->
            <!--</pattern>-->
        </encoder>
        <bootstrapServers>${bootstrapServers}</bootstrapServers>
        <topic>${topic}</topic>
        <batchSize>${batchSize}</batchSize>
        <lingerMs>${lingerMs}</lingerMs>
        <compressionType>${compressionType}</compressionType>
        <retries>${retries}</retries>
        <maxRequestSize>${maxRequestSize}</maxRequestSize>
        <isSend>${isSend}</isSend>
    </appender>
    <!--&lt;!&ndash; 使用logback-kafka-appender 当日志级别配为debug时,请使用该配置,不要使用root &ndash;&gt;-->
    <!--<logger name="com.demo.log2kafka" level="DEBUG">-->
    <!--<appender-ref ref="KAFKA"/>-->
    <!--</logger>-->
    <!-- 配置项用处,设置这个项目下,日志级别为debug (引用一上日志配置)  -->
    <root level="info">                               <!--就是说在整个项目中,日志级别在info一上的日志都打印-->
        <appender-ref ref="fileInfoLog"/>
        <appender-ref ref="fileErrorLog"/>
        <appender-ref ref="KAFKA"/>
    </root>
    <root level="info">                               <!--就是说在整个项目中,日志级别在info一上的日志都打印-->
        <appender-ref ref="fileDebugLog"/>
        <appender-ref ref="consoleLog"/>
        <appender-ref ref="KAFKA"/>
    </root>

</configuration>